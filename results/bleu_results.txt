BLEU (Bilingual Evaluation Understudy) ist eine Metrik zur Bewertung der Qualität von maschinellen Übersetzungen. Der BLEU-Score misst die Ähnlichkeit zwischen einer automatisch generierten Übersetzung und einer oder mehreren Referenzübersetzungen. Ein höherer BLEU-Score deutet darauf hin, dass die automatische Übersetzung besser mit den Referenzübersetzungen übereinstimmt.

BLEU Score für Vorhersage 1-1: 0.8646108953733144
BLEU Score für Vorhersage 2-1: 2.3394285299910343e-78
BLEU Score für Vorhersage 2-2: 2.3394285299910343e-78
BLEU Score für Vorhersage 2-3: 2.3394285299910343e-78
BLEU Score für Vorhersage 3-1: 1.0
BLEU Score für Vorhersage 3-2: 1.5319719891192393e-231
BLEU Score für Vorhersage 3-3: 1.821831989445342e-231
BLEU Score für Vorhersage 4-1: 0.4243775868805291

Durchschnittlicher BLEU-Score für das gesamte Dataset: 0.5722471205634609
