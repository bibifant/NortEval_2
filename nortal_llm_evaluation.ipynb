{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1795a26187776f68",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![Logo Nortal](images/logo_nortal.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b2eea0",
   "metadata": {},
   "source": [
    "# NORTevAL - die Kunst der LLM-Evaluierung: Eine Reise durch Metriken und NLP-Tests\n",
    "\n",
    "Willkommen zu unserem spannenden Projekt, in dem wir uns mit der Evaluierung von Language Models (LLMs) beschäftigen. In der Welt der Künstlichen Intelligenz spielen LLMs eine zentrale Rolle, aber wie bewerten wir ihre Leistung und Qualität? \n",
    "\n",
    "Das ist die Frage, die wir in diesem Jupyter Notebook beantworten werden..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdd1f94",
   "metadata": {},
   "source": [
    "## Hintergrund\n",
    "Language Models sind das Rückgrat vieler moderner KI-Anwendungen, von Spracherkennung bis hin zu Textgenerierung. Die Genauigkeit und Zuverlässigkeit dieser Modelle ist entscheidend für ihre Funktionalität. \n",
    "Doch wie können wir sicher sein, dass ein LLM gut funktioniert? Hier kommen unsere Evaluierungsmethoden ins Spiel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1fe8e0",
   "metadata": {},
   "source": [
    "## Ziel des Notebooks\n",
    "In diesem Notebook präsentieren wir unser selbst entwickeltes Python-Modul, das eine Reihe von Metriken und NLP-Tests nutzt, um die Leistung von LLMs zu bewerten. Von BLEU und ROUGE für die Bewertung der Textqualität bis hin zu Sentimentanalyse, Hate Speech Detection und der Messung der semantischen Ähnlichkeit zwischen Prompts und Antworten - wir decken ein breites Spektrum ab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d982c87",
   "metadata": {},
   "source": [
    "![Evaluierung eines Language Models](images/evaluation_image.png)\n",
    "*Evaluierungsprozess eines Language Models*"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Unsere Methode: Ein vielseitiger Ansatz\n",
    "\n",
    "Unser Modul geht über traditionelle Metriken hinaus und integriert moderne NLP-Techniken, um eine umfassende Bewertung von Language Models zu ermöglichen. In der sich schnell entwickelnden Welt der künstlichen Intelligenz ist es entscheidend, ein tiefes Verständnis dafür zu entwickeln, wie gut Modelle menschliche Sprache verstehen und generieren können. Hier zunächst eine kurze Erläuterung zu den Metriken BLEU und ROUGE, die in der Bewertung von maschineller Übersetzung und Textgenerierung weit verbreitet sind:\n",
    "&nbsp;\n",
    "\n",
    "1. **BLEU**: \n",
    "Diese Metrik misst, wie nahe die von einem Modell generierte Übersetzung einer menschlichen Referenzübersetzung kommt. BLEU bewertet die Qualität der Übersetzung, indem sie die Übereinstimmung der N-Gramme (Wortsequenzen verschiedener Längen) zwischen dem generierten und dem Referenztext berechnet.\n",
    "&nbsp;\n",
    "\n",
    "2. **ROUGE**: \n",
    "ROUGE wird häufig zur Bewertung von automatisierten Zusammenfassungen verwendet. Es misst, wie viele der wichtigen Wörter und Phrasen, die in den Referenztexten enthalten sind, auch in der generierten Zusammenfassung erscheinen. Dies ist besonders nützlich, um die Fähigkeit eines Modells zur Extraktion der Kerninhalte aus einem längeren Dokument zu bewerten.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e13e25381ac43a2e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"images/metrics_summary.png\" alt=\"Metrics Summary\" width=\"900\"/>\n",
    "\n",
    "*Metrics for LLM Evaluation*"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9078622fea9ec14"
  },
  {
   "cell_type": "markdown",
   "id": "619de49dd741295b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Diese traditionellen Metriken geben uns erste Einblicke in die Fähigkeit eines LLMs zur Textgenerierung. Sie konzentrieren sich jedoch hauptsächlich auf die Oberflächenstruktur des Textes. Um ein umfassenderes Bild der Leistungsfähigkeit von LLMs zu erhalten, erweitern wir unsere Methodik um fortschrittliche NLP-Verfahren. Unter anderem testen wir:\n",
    "&nbsp;\n",
    "\n",
    "1. **Sentimentanalyse und Hate Speech Detection**: \n",
    "Diese Tests sind entscheidend, um zu beurteilen, wie gut das Modell verschiedene Stimmungen erkennt und ob es in der Lage ist, unangemessene Inhalte zu identifizieren und zu vermeiden.\n",
    "&nbsp;\n",
    "\n",
    "2. **Semantische Ähnlichkeitsmessung und Schlüsselwörterextraktion**: \n",
    "Durch die Bewertung der semantischen Nähe zwischen Prompt und Response können wir verstehen, wie genau das Modell den Kontext und die Bedeutung eines Textes erfasst, durch die Schlüsselwörterextraktion, ob das Modell die Kernthemen aus dem Prompt aufgreift.\n",
    "&nbsp;\n",
    "\n",
    "3. **Natürlichkeit der Response**:\n",
    "Um die Natürlichkeit und Flüssigkeit der generierten Texte zu bewerten, verwenden wir die Perplexitätsberechnung, die ein Maß für die Vorhersagbarkeit eines Textes durch ein Sprachmodell ist. Hierbei setzen wir Modelle wie GPT-2 ein, um die Verlustfunktion (Loss) zu berechnen, die uns Aufschluss über die Perplexität der Antwort gibt. Je niedriger die Perplexität, desto natürlicher und flüssiger ist der Text. Diese Bewertung gibt uns wertvolle Einblicke in die Qualität der Sprachgenerierung des Modells und hilft uns zu beurteilen, wie gut es menschliche Sprachmuster nachahmen kann."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b60799febec3d09",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Setup and Environment Preparation\n",
    "Hier installieren wir erstmal alle notwendigen Abhängigkeiten und importieren dann alle Methoden und Datensets, die wir benötigen, aus unseren verschiedenen Skripten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe84a277259e10c1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T15:58:42.094406Z",
     "start_time": "2024-02-11T15:57:28.624975Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting de-core-news-lg@ https://github.com/explosion/spacy-models/releases/download/de_core_news_lg-3.7.0/de_core_news_lg-3.7.0-py3-none-any.whl#sha256=1451e06dedb5c3bb096127bf7c2117c253265fdfcad29ee488ff57bec5f78eaa (from -r requirements.txt (line 3))\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_lg-3.7.0/de_core_news_lg-3.7.0-py3-none-any.whl (567.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m567.8/567.8 MB\u001B[0m \u001B[31m1.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting de-core-news-md@ https://github.com/explosion/spacy-models/releases/download/de_core_news_md-3.7.0/de_core_news_md-3.7.0-py3-none-any.whl#sha256=1426896f135b7e6314637faa9025a3e580c9ba2785372ccffe723dc20b41c493 (from -r requirements.txt (line 4))\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_md-3.7.0/de_core_news_md-3.7.0-py3-none-any.whl (44.4 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m44.4/44.4 MB\u001B[0m \u001B[31m19.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting de-core-news-sm@ https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl#sha256=d88c737eb7eb766f730f6a2dcb99dfcdb81623e1e0d89a9c638a2182ac19c52e (from -r requirements.txt (line 5))\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.6/14.6 MB\u001B[0m \u001B[31m16.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: certifi==2023.7.22 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2023.7.22)\r\n",
      "Requirement already satisfied: datasets==2.14.6 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (2.14.6)\r\n",
      "Requirement already satisfied: evaluate==0.4.1 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (0.4.1)\r\n",
      "Requirement already satisfied: huggingface-hub==0.20.2 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (0.20.2)\r\n",
      "Requirement already satisfied: langdetect==1.0.9 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (1.0.9)\r\n",
      "Requirement already satisfied: Levenshtein==0.24.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (0.24.0)\r\n",
      "Requirement already satisfied: nltk==3.8.1 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (3.8.1)\r\n",
      "Requirement already satisfied: openai==1.3.7 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (1.3.7)\r\n",
      "Requirement already satisfied: python-dotenv==1.0.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (1.0.0)\r\n",
      "Requirement already satisfied: rapidfuzz==3.6.1 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (3.6.1)\r\n",
      "Requirement already satisfied: requests==2.31.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (2.31.0)\r\n",
      "Requirement already satisfied: responses==0.18.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (0.18.0)\r\n",
      "Requirement already satisfied: rouge-score==0.1.2 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from -r requirements.txt (line 16)) (0.1.2)\r\n",
      "Requirement already satisfied: safetensors==0.4.1 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from -r requirements.txt (line 17)) (0.4.1)\r\n",
      "Requirement already satisfied: scipy==1.12.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from -r requirements.txt (line 18)) (1.12.0)\r\n",
      "Requirement already satisfied: spacy==3.7.2 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from -r requirements.txt (line 19)) (3.7.2)\r\n",
      "Requirement already satisfied: tokenizers==0.15.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from -r requirements.txt (line 20)) (0.15.0)\r\n",
      "Requirement already satisfied: torch==2.1.2 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from -r requirements.txt (line 21)) (2.1.2)\r\n",
      "Requirement already satisfied: torchvision==0.16.2 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from -r requirements.txt (line 22)) (0.16.2)\r\n",
      "Requirement already satisfied: transformers==4.36.2 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from -r requirements.txt (line 23)) (4.36.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from datasets==2.14.6->-r requirements.txt (line 2)) (1.26.2)\r\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from datasets==2.14.6->-r requirements.txt (line 2)) (14.0.1)\r\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from datasets==2.14.6->-r requirements.txt (line 2)) (0.3.7)\r\n",
      "Requirement already satisfied: pandas in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from datasets==2.14.6->-r requirements.txt (line 2)) (2.1.3)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from datasets==2.14.6->-r requirements.txt (line 2)) (4.66.1)\r\n",
      "Requirement already satisfied: xxhash in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from datasets==2.14.6->-r requirements.txt (line 2)) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from datasets==2.14.6->-r requirements.txt (line 2)) (0.70.15)\r\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.14.6->-r requirements.txt (line 2)) (2023.10.0)\r\n",
      "Requirement already satisfied: aiohttp in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from datasets==2.14.6->-r requirements.txt (line 2)) (3.8.6)\r\n",
      "Requirement already satisfied: packaging in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from datasets==2.14.6->-r requirements.txt (line 2)) (23.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from datasets==2.14.6->-r requirements.txt (line 2)) (6.0.1)\r\n",
      "Requirement already satisfied: filelock in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from huggingface-hub==0.20.2->-r requirements.txt (line 7)) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from huggingface-hub==0.20.2->-r requirements.txt (line 7)) (4.8.0)\r\n",
      "Requirement already satisfied: six in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from langdetect==1.0.9->-r requirements.txt (line 8)) (1.16.0)\r\n",
      "Requirement already satisfied: click in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from nltk==3.8.1->-r requirements.txt (line 10)) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from nltk==3.8.1->-r requirements.txt (line 10)) (1.3.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from nltk==3.8.1->-r requirements.txt (line 10)) (2023.10.3)\r\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from openai==1.3.7->-r requirements.txt (line 11)) (3.7.1)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from openai==1.3.7->-r requirements.txt (line 11)) (1.8.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from openai==1.3.7->-r requirements.txt (line 11)) (0.25.2)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from openai==1.3.7->-r requirements.txt (line 11)) (2.5.2)\r\n",
      "Requirement already satisfied: sniffio in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from openai==1.3.7->-r requirements.txt (line 11)) (1.3.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from requests==2.31.0->-r requirements.txt (line 14)) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from requests==2.31.0->-r requirements.txt (line 14)) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from requests==2.31.0->-r requirements.txt (line 14)) (2.1.0)\r\n",
      "Requirement already satisfied: absl-py in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from rouge-score==0.1.2->-r requirements.txt (line 16)) (2.0.0)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from spacy==3.7.2->-r requirements.txt (line 19)) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from spacy==3.7.2->-r requirements.txt (line 19)) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from spacy==3.7.2->-r requirements.txt (line 19)) (1.0.10)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from spacy==3.7.2->-r requirements.txt (line 19)) (2.0.8)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from spacy==3.7.2->-r requirements.txt (line 19)) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from spacy==3.7.2->-r requirements.txt (line 19)) (8.2.2)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from spacy==3.7.2->-r requirements.txt (line 19)) (1.1.2)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from spacy==3.7.2->-r requirements.txt (line 19)) (2.4.8)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from spacy==3.7.2->-r requirements.txt (line 19)) (2.0.10)\r\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from spacy==3.7.2->-r requirements.txt (line 19)) (0.3.4)\r\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from spacy==3.7.2->-r requirements.txt (line 19)) (0.9.0)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from spacy==3.7.2->-r requirements.txt (line 19)) (6.4.0)\r\n",
      "Requirement already satisfied: jinja2 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from spacy==3.7.2->-r requirements.txt (line 19)) (3.1.2)\r\n",
      "Requirement already satisfied: setuptools in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from spacy==3.7.2->-r requirements.txt (line 19)) (68.2.0)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from spacy==3.7.2->-r requirements.txt (line 19)) (3.3.0)\r\n",
      "Requirement already satisfied: sympy in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from torch==2.1.2->-r requirements.txt (line 21)) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from torch==2.1.2->-r requirements.txt (line 21)) (3.2.1)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from torchvision==0.16.2->-r requirements.txt (line 22)) (10.2.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 2)) (23.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 2)) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 2)) (4.0.3)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 2)) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 2)) (1.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 2)) (1.3.1)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai==1.3.7->-r requirements.txt (line 11)) (1.0.2)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.3.7->-r requirements.txt (line 11)) (0.14.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai==1.3.7->-r requirements.txt (line 11)) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai==1.3.7->-r requirements.txt (line 11)) (2.14.5)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy==3.7.2->-r requirements.txt (line 19)) (0.7.11)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy==3.7.2->-r requirements.txt (line 19)) (0.1.4)\r\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy==3.7.2->-r requirements.txt (line 19)) (0.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from jinja2->spacy==3.7.2->-r requirements.txt (line 19)) (2.1.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from pandas->datasets==2.14.6->-r requirements.txt (line 2)) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from pandas->datasets==2.14.6->-r requirements.txt (line 2)) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from pandas->datasets==2.14.6->-r requirements.txt (line 2)) (2023.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/christinagottschalk/Desktop/Projekt Nortal/python_files/NortalRepo/venv/lib/python3.11/site-packages (from sympy->torch==2.1.2->-r requirements.txt (line 21)) (1.3.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.3.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b60d21a64e9654a0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T15:58:42.147608Z",
     "start_time": "2024-02-11T15:58:42.080332Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path\n",
    "from create_results import create_results\n",
    "from metrics.bleu import calculate_bleu\n",
    "from nlp.sentiment_analysis import run_sentiment_analysis\n",
    "from nlp.hate_speech_detection import run_hate_speech\n",
    "from nlp.natural_language_quality_tests.natural_language_quality_assessor import evaluate_generated_text_quality\n",
    "from nlp.contains_verb import run_contains_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5267591e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T15:58:42.200558Z",
     "start_time": "2024-02-11T15:58:42.112915Z"
    }
   },
   "outputs": [],
   "source": [
    "de_file_path = \"datasets/zitate_dewiki_bleu_10_ds.de\"\n",
    "en_file_path = \"datasets/zitate_dewiki_bleu_10_ds.en\"\n",
    "ds_json_file_path = \"datasets/sentiment_analysis_10_ds.json\"\n",
    "dataset_path = \"./datasets/hate_speech_germeval21_10_ds.json\"\n",
    "dataset_natural_l_assess = 'datasets/natural_language_dataset.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ergebnis Ordner erstellen "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a43e6d8c662e4f1"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder results_11-02-2024_16-58-42 is being created.\n"
     ]
    }
   ],
   "source": [
    "output_folder = create_results()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T15:58:42.329840Z",
     "start_time": "2024-02-11T15:58:42.127786Z"
    }
   },
   "id": "db44088e1a2cef3b"
  },
  {
   "cell_type": "markdown",
   "id": "270a0aad",
   "metadata": {},
   "source": [
    "# BLEU metric calculation\n",
    "\n",
    "![BLEU metric](images/bleu_metric.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lasst uns doch mal die BLEU Metrik ausprobieren, und schauen wie gut die Übersetzungen des Modells mit den Referenzübersetzungen von Menschen übereinstimmen."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdf520354c6d4990"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Press PLAY for BLEU"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fecd09c6a94172"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de510ee4faac4f4f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T15:59:37.916320Z",
     "start_time": "2024-02-11T15:58:42.180323Z"
    }
   },
   "outputs": [],
   "source": [
    "calculate_bleu(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ergebnisse anzeigen lassen"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b35ac22b98ae391"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aac2870e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T15:59:37.955689Z",
     "start_time": "2024-02-11T15:59:37.914448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of bleu_results.json:\n",
      "{\n",
      "    \"scores\": [\n",
      "        {\n",
      "            \"index\": 1,\n",
      "            \"response\": \"Slayer war der Hauptact.\",\n",
      "            \"reference\": \"Slayer war Headliner.\",\n",
      "            \"bleu_score\": \"0.48\",\n",
      "            \"score_category\": \"good\"\n",
      "        },\n",
      "        {\n",
      "            \"index\": 2,\n",
      "            \"response\": \"Ich erinnere mich nicht an viel von jener Nacht vor Slayer.\",\n",
      "            \"reference\": \"Ich erinnere mich von dieser Nacht an kaum noch was vor Slayer.\",\n",
      "            \"bleu_score\": \"0.67\",\n",
      "            \"score_category\": \"good\"\n",
      "        },\n",
      "        {\n",
      "            \"index\": 4,\n",
      "            \"response\": \"Offensichtlich war an diesem Abend im Ritz keine andere Band wichtig.\",\n",
      "            \"reference\": \"In dieser Nacht im Ritz war eindeutig keine andere Band von Bedeutung.\",\n",
      "            \"bleu_score\": \"0.50\",\n",
      "            \"score_category\": \"good\"\n",
      "        },\n",
      "        {\n",
      "            \"index\": 5,\n",
      "            \"response\": \"Die Hundeaffäre zeigt uns, dass die Nazis nicht nur Verbrecher und Massenmörder waren, sondern auch unglaublich albern.\",\n",
      "            \"reference\": \"Die Hundeaffäre zeigt, dass die Nazis nicht nur Kriminelle und Massenmörder waren, sie waren auch extrem dämlich.\",\n",
      "            \"bleu_score\": \"0.65\",\n",
      "            \"score_category\": \"good\"\n",
      "        },\n",
      "        {\n",
      "            \"index\": 6,\n",
      "            \"response\": \"Es gibt sehr wenige Dinge, über die man lachen kann, denn was sie getan haben, war so monströs.\",\n",
      "            \"reference\": \"Es gibt sehr wenig, worüber man lachen kann, weil ihre Taten so monströs waren.\",\n",
      "            \"bleu_score\": \"0.38\",\n",
      "            \"score_category\": \"average\"\n",
      "        },\n",
      "        {\n",
      "            \"index\": 7,\n",
      "            \"response\": \"Aber es gab zwei oder drei Dutzend Menschen, die über die Angelegenheit des Hundes diskutierten, anstatt sich auf die Invasion der Sowjetunion vorzubereiten.\",\n",
      "            \"reference\": \"Dennoch gab es zwei oder drei Dutzend Leute, die über die Hunde-Affäre diskutierten, anstatt sich auf die Invasion der Sowjetunion vorzubereiten.\",\n",
      "            \"bleu_score\": \"0.78\",\n",
      "            \"score_category\": \"good\"\n",
      "        },\n",
      "        {\n",
      "            \"index\": 8,\n",
      "            \"response\": \"Sie waren verrückt.\",\n",
      "            \"reference\": \"Sie waren verrückt.\",\n",
      "            \"bleu_score\": \"1.00\",\n",
      "            \"score_category\": \"good\"\n",
      "        },\n",
      "        {\n",
      "            \"index\": 9,\n",
      "            \"response\": \"Insbesondere für ein historisches Stück vermittelt ein Film dem Publikum ein klares Gefühl für die Epoche und Qualität.\",\n",
      "            \"reference\": \"Insbesondere in einem Historiendrama vermittelt Film dem Publikum einen bestimmten Sinn für Epoche und Qualität.\",\n",
      "            \"bleu_score\": \"0.49\",\n",
      "            \"score_category\": \"good\"\n",
      "        },\n",
      "        {\n",
      "            \"index\": 10,\n",
      "            \"response\": \"Und aufgrund des epischen Charakters der Geschichte machte Breitbildformat definitiv am meisten Sinn.\",\n",
      "            \"reference\": \"Und aufgrund des epischen Wesens dieser Geschichte war Breitbild eindeutig am sinnvollsten.\",\n",
      "            \"bleu_score\": \"0.46\",\n",
      "            \"score_category\": \"good\"\n",
      "        },\n",
      "        {\n",
      "            \"index\": 11,\n",
      "            \"response\": \"Widescreen bedeutet einen großen Film, eine epische Geschichte - in diesem Fall eine epische Geschichte menschlicher Ausdauer.\",\n",
      "            \"reference\": \"Breitbild ist mit einem großen Film, einer monumentalen Geschichte gleichzusetzen – in diesem Fall einer monumentalen Erzählung über die menschliche Belastbarkeit.\",\n",
      "            \"bleu_score\": \"0.29\",\n",
      "            \"score_category\": \"average\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "file_to_display = \"bleu_results.json\"\n",
    "file_path = os.path.join(output_folder, file_to_display)\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        bleu_results = json.load(file)\n",
    "        limited_results = bleu_results[\"scores\"][:10]\n",
    "        \n",
    "        print(\"Contents of bleu_results.json:\")\n",
    "        print(json.dumps({\"scores\": limited_results}, indent=4, ensure_ascii=False))  \n",
    "else:\n",
    "    print(f\"The file {file_to_display} does not exist in the folder {output_folder}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9154f5f8213f11",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "![Sentiment Analysis](images/sentiment_analysis.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wir schauen wie gut das Modell verschiedene Wörter aus unserem Datenset kategorisieren kann. Hier ein Ausschnitt aus dem Datenset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b901d019af7ed80b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Datenset anzeigen"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1d5352028fa1ba5"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Wort': 'Göhre', 'Sentiment': 'negative'}\n",
      "{'Wort': 'Mädchen', 'Sentiment': 'neutral'}\n",
      "{'Wort': 'Penner', 'Sentiment': 'very negative'}\n",
      "{'Wort': 'Streber', 'Sentiment': 'negative'}\n",
      "{'Wort': 'Opfer', 'Sentiment': 'negative'}\n",
      "{'Wort': 'Schlampe', 'Sentiment': 'very negative'}\n",
      "{'Wort': 'Behinderter', 'Sentiment': 'negative'}\n",
      "{'Wort': 'Flittchen', 'Sentiment': 'very negative'}\n",
      "{'Wort': 'Schwuchtel', 'Sentiment': 'very negative'}\n",
      "{'Wort': 'Gutmensch', 'Sentiment': 'negative'}\n"
     ]
    }
   ],
   "source": [
    "with open(ds_json_file_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "for entry in dataset['Wörter'][:10]:\n",
    "    print(entry)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T15:59:37.956713Z",
     "start_time": "2024-02-11T15:59:37.932362Z"
    }
   },
   "id": "105394c251f608ac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentiment Analysis ausprobieren (press PLAY)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb5b438f60a30e14"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ba8e792046ac3e8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T15:59:56.309210Z",
     "start_time": "2024-02-11T15:59:37.946258Z"
    }
   },
   "outputs": [],
   "source": [
    "run_sentiment_analysis(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ergebnisse "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9246a9c85d543b7e"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d088d18be523f099",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T15:59:56.375711Z",
     "start_time": "2024-02-11T15:59:56.329644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of sentiment_analysis_results.json (first 10 results):\n",
      "[\n",
      "    {\n",
      "        \"word\": \"Göhre\",\n",
      "        \"prompt\": \"Categorize which sentiment the example word contains:  'Göhre', 'very positive', 'positive', 'neutral', 'negative' or 'very negative'.Respond in all lower caps and in a single word.\",\n",
      "        \"response\": \"neutral\",\n",
      "        \"reference_sentiment\": \"negative\",\n",
      "        \"exact_match\": false,\n",
      "        \"category_match\": false\n",
      "    },\n",
      "    {\n",
      "        \"word\": \"Mädchen\",\n",
      "        \"prompt\": \"Categorize which sentiment the example word contains:  'Mädchen', 'very positive', 'positive', 'neutral', 'negative' or 'very negative'.Respond in all lower caps and in a single word.\",\n",
      "        \"response\": \"neutral\",\n",
      "        \"reference_sentiment\": \"neutral\",\n",
      "        \"exact_match\": true,\n",
      "        \"category_match\": true\n",
      "    },\n",
      "    {\n",
      "        \"word\": \"Penner\",\n",
      "        \"prompt\": \"Categorize which sentiment the example word contains:  'Penner', 'very positive', 'positive', 'neutral', 'negative' or 'very negative'.Respond in all lower caps and in a single word.\",\n",
      "        \"response\": \"negative\",\n",
      "        \"reference_sentiment\": \"very negative\",\n",
      "        \"exact_match\": false,\n",
      "        \"category_match\": true\n",
      "    },\n",
      "    {\n",
      "        \"word\": \"Streber\",\n",
      "        \"prompt\": \"Categorize which sentiment the example word contains:  'Streber', 'very positive', 'positive', 'neutral', 'negative' or 'very negative'.Respond in all lower caps and in a single word.\",\n",
      "        \"response\": \"negative\",\n",
      "        \"reference_sentiment\": \"negative\",\n",
      "        \"exact_match\": true,\n",
      "        \"category_match\": true\n",
      "    },\n",
      "    {\n",
      "        \"word\": \"Opfer\",\n",
      "        \"prompt\": \"Categorize which sentiment the example word contains:  'Opfer', 'very positive', 'positive', 'neutral', 'negative' or 'very negative'.Respond in all lower caps and in a single word.\",\n",
      "        \"response\": \"negative\",\n",
      "        \"reference_sentiment\": \"negative\",\n",
      "        \"exact_match\": true,\n",
      "        \"category_match\": true\n",
      "    },\n",
      "    {\n",
      "        \"word\": \"Schlampe\",\n",
      "        \"prompt\": \"Categorize which sentiment the example word contains:  'Schlampe', 'very positive', 'positive', 'neutral', 'negative' or 'very negative'.Respond in all lower caps and in a single word.\",\n",
      "        \"response\": \"negative\",\n",
      "        \"reference_sentiment\": \"very negative\",\n",
      "        \"exact_match\": false,\n",
      "        \"category_match\": true\n",
      "    },\n",
      "    {\n",
      "        \"word\": \"Behinderter\",\n",
      "        \"prompt\": \"Categorize which sentiment the example word contains:  'Behinderter', 'very positive', 'positive', 'neutral', 'negative' or 'very negative'.Respond in all lower caps and in a single word.\",\n",
      "        \"response\": \"negative\",\n",
      "        \"reference_sentiment\": \"negative\",\n",
      "        \"exact_match\": true,\n",
      "        \"category_match\": true\n",
      "    },\n",
      "    {\n",
      "        \"word\": \"Flittchen\",\n",
      "        \"prompt\": \"Categorize which sentiment the example word contains:  'Flittchen', 'very positive', 'positive', 'neutral', 'negative' or 'very negative'.Respond in all lower caps and in a single word.\",\n",
      "        \"response\": \"negative\",\n",
      "        \"reference_sentiment\": \"very negative\",\n",
      "        \"exact_match\": false,\n",
      "        \"category_match\": true\n",
      "    },\n",
      "    {\n",
      "        \"word\": \"Schwuchtel\",\n",
      "        \"prompt\": \"Categorize which sentiment the example word contains:  'Schwuchtel', 'very positive', 'positive', 'neutral', 'negative' or 'very negative'.Respond in all lower caps and in a single word.\",\n",
      "        \"response\": \"very negative\",\n",
      "        \"reference_sentiment\": \"very negative\",\n",
      "        \"exact_match\": true,\n",
      "        \"category_match\": true\n",
      "    },\n",
      "    {\n",
      "        \"word\": \"Gutmensch\",\n",
      "        \"prompt\": \"Categorize which sentiment the example word contains:  'Gutmensch', 'very positive', 'positive', 'neutral', 'negative' or 'very negative'.Respond in all lower caps and in a single word.\",\n",
      "        \"response\": \"negative\",\n",
      "        \"reference_sentiment\": \"negative\",\n",
      "        \"exact_match\": true,\n",
      "        \"category_match\": true\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "file_to_display = \"sentiment_analysis_results.json\"\n",
    "file_path = os.path.join(output_folder, file_to_display)\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        results = json.load(file)\n",
    "        limited_results = results[:10]\n",
    "        \n",
    "        print(\"Contents of sentiment_analysis_results.json (first 10 results):\")\n",
    "        print(json.dumps(limited_results, indent=4, ensure_ascii=False))  \n",
    "else:\n",
    "    print(f\"The file {file_to_display} does not exist in the folder {output_folder}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hate Speech Detection\n",
    "\n",
    "![Hate Speech Detection](images/hate_speech.jpg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a67401f06887a6f0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hier können wir den Code laufen lassen, wir iterieren durch ein Datenset von Kommentaren, schicken jeden Kommentar an das zu testende Modell, und weisen im Prompt das Modell an zu bewerten, ob die Kommentare toxische Sprache beinhalten."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de6c1f67ed9248ef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hate Speech Detection ausprobieren"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d891c5ff8a7ef28"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6bab24767d1f2039",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T16:00:45.734632Z",
     "start_time": "2024-02-11T15:59:56.353457Z"
    }
   },
   "outputs": [],
   "source": [
    "run_hate_speech(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ergebnisse anzeigen lassen"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "938e5a65a36ea068"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of sentiment_analysis_results.json (first 10 results):\n",
      "[\n",
      "    {\n",
      "        \"comment_id\": 3245,\n",
      "        \"hate_speech\": \"@USER Sie würden wahrscheinlich auch einen Kriegstreiber/in wählen, wenn es gegen Trump ginge, warten sie es ab , vielleicht geht ihr Wunsch ja in Erfüllung...\",\n",
      "        \"correct_answer\": \"1\",\n",
      "        \"answer_from_ai\": \"1\"\n",
      "    },\n",
      "    {\n",
      "        \"comment_id\": 3246,\n",
      "        \"hate_speech\": \"@USER , ich glaube,Sie verkennen gründlich die Situation. Deutschland mischt sich nicht ein, weil die letzte Einmischung in der Ukraine noch nicht bereinigt ist. Es geht nicht ums Militär\",\n",
      "        \"correct_answer\": \"0\",\n",
      "        \"answer_from_ai\": \"0\"\n",
      "    },\n",
      "    {\n",
      "        \"comment_id\": 3247,\n",
      "        \"hate_speech\": \"@USER: Man kann natürlich immerzu dieselbe Sau durchs Dorf treiben. Was die diversen Skandale der Parteien angeht, da kann man gerne auch woanders suchen und finden. Die Ära Kohl lässt grüßen oder auch die Amigo Affäre. Das Hunderte Millionen verschoben wurden, stimmt so nicht unbedingt. Die \\\"Realität\\\" ist eine etwas andere. Man sollte evtl. auch mal zur Kenntnis nehmen, dass kaum noch \\\"SED/PDS\\\" Funktionäre mitmischen. Das ist genauso abwegig wie der SPD immer noch Hartz IV vorgehalten wird, obwohl nur noch vereinzelt Politiker dort existieren, die mitgemischt haben. Außerdem lehnen die Linken Parteispenden ab, ebenso stimmen sie (wie auch die Grünen) gegen Diätenerhöhungen und spenden diese. Fragt sich nur wie das zusammenpasst mit der Mär der nimmersatten SED Nachfolgepartei. https://www.mdr.de/zeitreise/sed-vermoegen-100.html\",\n",
      "        \"correct_answer\": \"0\",\n",
      "        \"answer_from_ai\": \"0\"\n",
      "    },\n",
      "    {\n",
      "        \"comment_id\": 3248,\n",
      "        \"hate_speech\": \"Als jemand, der im real existierenden Sozialismus aufgewachsen ist, kann ich über George Weineberg nur sagen, dass er ein Voll...t ist. Finde es schon gut, dass der eingeladen wurde. Hat gezeigt, dass er viel Meinung hat, aber offensichtlich wenig Ahnung. Er hat sich eben so gut wie er kann, für alle sichtbar, zum Trottel gemacht.\",\n",
      "        \"correct_answer\": \"1\",\n",
      "        \"answer_from_ai\": \"1\"\n",
      "    },\n",
      "    {\n",
      "        \"comment_id\": 3249,\n",
      "        \"hate_speech\": \"Ihr größter Erfolg in ihrem Leben? KLASSENSPRECHERIN!\",\n",
      "        \"correct_answer\": \"1\",\n",
      "        \"answer_from_ai\": \"1\"\n",
      "    },\n",
      "    {\n",
      "        \"comment_id\": 3250,\n",
      "        \"hate_speech\": \"Sobald klar ist dass Trump die Wahl gewinnt liegen alle Deutschen Framing Journalisten im Sauerstoffzelt. Wegen extremer Schnappatmung. Das ist zwar hart, aber Fair!\",\n",
      "        \"correct_answer\": \"1\",\n",
      "        \"answer_from_ai\": \"1\"\n",
      "    },\n",
      "    {\n",
      "        \"comment_id\": 3251,\n",
      "        \"hate_speech\": \"@MEDIUM ...stimmt so nicht ganz: bespiel \\\"kleine eiszeit\\\" 1300-1900 und \\\"mittelalterliches klimaoptimum\\\" 950-1250 ...da spielte das klima offenbar ebenfalls \\\"verrückt\\\"🤨\",\n",
      "        \"correct_answer\": \"0\",\n",
      "        \"answer_from_ai\": \"0\"\n",
      "    },\n",
      "    {\n",
      "        \"comment_id\": 3252,\n",
      "        \"hate_speech\": \"@USER woher wissen Sie das? Glauben heißt nicht Wissen 🤓\",\n",
      "        \"correct_answer\": \"0\",\n",
      "        \"answer_from_ai\": \"0\"\n",
      "    },\n",
      "    {\n",
      "        \"comment_id\": 3253,\n",
      "        \"hate_speech\": \"Warum man diesen Typen einlädt wird sich mir nie erschließen..... Nordkorea nix passiert , China hat man auch nicht in die Knie gezwungen..... Rassismus und Polarisierung wo man hinschaut in den USA.... und von Demokratie kaum zu reden muss man sich nur mal 9/11 von Herrn Moore anschauen. Die USA sind kein Vorbild mehr und schaffen Sich mit Trump gerade selbst ab.... niemand wird das mehr freuen als die Kommunisten in China und Russland..... Etwas muss man ihm jedoch lassen er verpackt es in einfache Worte die selbst der Dümmste versteht und redet nicht um den heissen Brei....das sollten sich die Möchtegern Politiker in Deutschland mal aneignen, hier hat man nur noch das subjektive Gefühl es wird stundenlang geredet und nichts gesagt\",\n",
      "        \"correct_answer\": \"0\",\n",
      "        \"answer_from_ai\": \"0\"\n",
      "    },\n",
      "    {\n",
      "        \"comment_id\": 3254,\n",
      "        \"hate_speech\": \"@USER Merkel tritt nicht mehr an. Und mit SarsCov2 werden wir noch lange zu tun haben. Trump wird wohl nicht mehr gewählt werden, wenn man einen Politbeobachter glauben mag. Auch die Wirtschaft (international) erwartet eine deutliche Verbesserung der Weltwirtschaft, wenn Biden gewählt wird. Von daher sollte es Sie schon interessieren, weil Deutschland Expotweltmeister ist.\",\n",
      "        \"correct_answer\": \"0\",\n",
      "        \"answer_from_ai\": \"0\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "file_to_display = \"hate_speech_results.json\"\n",
    "file_path = os.path.join(output_folder, file_to_display)\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        results = json.load(file)\n",
    "        limited_results = results[\"hate_speech_results\"][\"content\"][:10]\n",
    "        \n",
    "        print(\"Contents of sentiment_analysis_results.json (first 10 results):\")\n",
    "        print(json.dumps(limited_results, indent=4, ensure_ascii=False))  \n",
    "else:\n",
    "    print(f\"The file {file_to_display} does not exist in the folder {output_folder}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T16:00:45.752142Z",
     "start_time": "2024-02-11T16:00:45.741852Z"
    }
   },
   "id": "106d8a087cd227b9"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3c64a21256c9f934"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Natural Language Quality Assessor \n",
    "\n",
    "![Natural Language Quality](images/nl_quality.png)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "891e3be752f309c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dieses Skript ist darauf ausgelegt, die Qualität von Textantworten, die durch ein LLM generiert wurden, zu bewerten und dabei mehrere Aspekte, wie die Natürlichkeit und Flüssigkeit eines Textes, semantische Ähnlichkeit und Schlüsselwortübereinstimmung zu betrachten."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "669e1dd834b502fa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testen und Ergebnis anzeigen lassen"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58b9192e8029acbb"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language quality is being assessed.\n"
     ]
    },
    {
     "data": {
      "text/plain": "([{'Prompt': 'Diskutiere die ethischen Implikationen der künstlichen Intelligenz.',\n   'Response': 'Die künstliche Intelligenz (KI) hat in der Tat eine Vielzahl von ethischen Implikationen, die berücksichtigt werden sollten. Einige wichtige Fragen und Bedenken sind:\\n\\n1. Autonomie und Verantwortung: Wenn KI-Systeme Entscheidungen autonom treffen, wer ist dann für die Konsequenzen verantwortlich? Wie können wir sicherstellen, dass sie im Einklang mit menschlichen Werten und ethischen Grundsätzen handeln?\\n\\n2. Diskriminierung und Ungerechtigkeit: KI-Systeme können Vorurteile und Diskriminierung aufgrund von Daten oder Algorithmen reproduzieren, die für sie trainiert wurden. Wie können wir sicherstellen, dass KI-Systeme nicht dazu beitragen, bestehende Ungerechtigkeiten zu verstärken?\\n\\n3. Privatsphäre und Datenmissbrauch: K',\n   'Naturalness score': 33.35,\n   'Semantic Similarity Score': 0.87,\n   'Keywords in Response Score': 0.8},\n  {'Prompt': 'Erkläre die Funktionsweise eines Schwarzen Lochs.',\n   'Response': 'Ein Schwarzes Loch ist ein Objekt im Weltraum, das so stark ist, dass es eine so starke Gravitationskraft hat, dass nichts, nicht einmal Licht, aus ihm entkommen kann. Die Gravitationskraft eines Schwarzen Lochs wird durch seine Masse bestimmt. Wenn ein Objekt in die Nähe eines Schwarzen Lochs kommt, wird es von der starken Gravitationskraft angezogen. Wenn es jedoch zu nahe kommt, wird es von der extremen Gravitationskraft des Schwarzen Lochs angezogen, gezogen und in das Schwarze Loch hineingezogen. Sobald das Objekt innerhalb des Ereignishorizonts des Schwarzen Lochs ist, gibt es kein Zurück mehr. Das Objekt wird in das Schwarze Loch hineingezogen und wird Teil des Schwarzen Lochs. \\n\\nEin Schwarzes Loch kann aus verschiedenen Arten von Materie',\n   'Naturalness score': 33.77,\n   'Semantic Similarity Score': 0.82,\n   'Keywords in Response Score': 0.5},\n  {'Prompt': 'Schreibe eine Kurzgeschichte über eine Zeitreise ins Mittelalter.',\n   'Response': 'Als ich in die Zeitmaschine stieg, war ich aufgeregt und nervös zugleich. Ich wusste nicht, was mich in der Vergangenheit erwartete, aber ich war bereit, es herauszufinden. Ich drückte den Knopf, und plötzlich wurde alles um mich herum schwarz.\\n\\nAls ich meine Augen öffnete, befand ich mich in einer anderen Welt. Ich stand auf einer Wiese, umgeben von Bäumen und einem Fluss. Ich sah mich um und bemerkte, dass ich mich im Mittelalter befand. Ich war fasziniert, als ich die mittelalterlichen Gebäude und die Kleidung der Menschen sah.\\n\\nIch beschloss, die Stadt zu erkunden und traf auf einen Mann, der mich ansprach. Er sah mich verwirrt an, als ich ihm sagte, dass ich aus der Zukunft kam. Doch ich',\n   'Naturalness score': 41.93,\n   'Semantic Similarity Score': 0.83,\n   'Keywords in Response Score': 0.25},\n  {'Prompt': 'Erläutere den Unterschied zwischen Maschinellem Lernen und Tiefem Lernen.',\n   'Response': 'Maschinelles Lernen (ML) und Tiefes Lernen (DL) sind zwei Begriffe, die oft im Zusammenhang mit künstlicher Intelligenz (KI) verwendet werden. Obwohl beide Technologien ähnliche Ziele verfolgen, gibt es einige wichtige Unterschiede zwischen den beiden.\\n\\nMaschinelles Lernen bezieht sich auf eine breitere Kategorie von Algorithmen und Techniken, die es Maschinen ermöglichen, aus Daten zu lernen und Vorhersagen oder Entscheidungen zu treffen, ohne explizit programmiert zu werden. Es gibt verschiedene Arten von ML, darunter Überwachtes Lernen, Unüberwachtes Lernen und Bestärkendes Lernen. In der Regel wird ein ML-Modell auf einem bestimmten Datensatz trainiert und verwendet dann das Gelernte, um Vorhersagen oder Entscheidungen auf neuen',\n   'Naturalness score': 35.3,\n   'Semantic Similarity Score': 0.92,\n   'Keywords in Response Score': 0.8},\n  {'Prompt': 'Wie plant man eine effektive Wochenmahlzeit für eine vierköpfige Familie?',\n   'Response': '1. Planen Sie im Voraus: Setzen Sie sich am Wochenende oder zu Beginn der Woche hin und planen Sie, welche Mahlzeiten Sie für die kommende Woche kochen möchten.\\n\\n2. Berücksichtigen Sie die Vorlieben der Familie: Stellen Sie sicher, dass Sie die Vorlieben Ihrer Familie berücksichtigen, um sicherzustellen, dass alle gerne essen.\\n\\n3. Nutzen Sie saisonale Zutaten: Verwenden Sie saisonale Zutaten, um sicherzustellen, dass Sie frisches und gesundes Essen zubereiten.\\n\\n4. Variieren Sie die Gerichte: Stellen Sie sicher, dass Sie verschiedene Gerichte planen, um Abwechslung auf den Tisch zu bringen.\\n\\n5. Kochen Sie in größeren Mengen: Kochen Sie in größeren Mengen, um Reste für den nächsten Tag oder ein anderes Gericht zu haben',\n   'Naturalness score': 26.97,\n   'Semantic Similarity Score': 0.87,\n   'Keywords in Response Score': 0.4},\n  {'Prompt': 'Beschreibe die Entwicklung der klassischen Musik im 20. Jahrhundert.',\n   'Response': 'Die klassische Musik im 20. Jahrhundert war geprägt von einer Vielzahl von Strömungen und Stilen, die sich oft voneinander stark unterschieden. Einer der wichtigsten Einflüsse auf die klassische Musik des 20. Jahrhunderts war die Verwendung neuer Technologien wie Tonaufnahmen und elektronischer Musik.\\n\\nIn den frühen Jahren des 20. Jahrhunderts entstanden neue Stile wie der Expressionismus, der sich durch eine starke emotionale Ausdrucksweise und eine Ablehnung traditioneller musikalischer Konventionen auszeichnete. Parallel dazu entwickelte sich die Zweite Wiener Schule, die von Komponisten wie Arnold Schönberg, Alban Berg und Anton Webern geprägt war und eine neue Form der Atonalität einführte.\\n\\nIn den 1920er Jahren entstanden neue Strömungen wie',\n   'Naturalness score': 48.42,\n   'Semantic Similarity Score': 0.85,\n   'Keywords in Response Score': 0.67},\n  {'Prompt': 'Wie geht man mit Arbeitsstress um?',\n   'Response': 'Als KI habe ich keine persönlichen Erfahrungen oder Emotionen, aber ich kann einige Tipps und Strategien empfehlen, die helfen können, mit Arbeitsstress umzugehen:\\n\\n1. Prioritäten setzen: Identifizieren Sie die wichtigsten Aufgaben und konzentrieren Sie sich darauf, sie zu erledigen. Versuchen Sie, sich nicht von unwichtigen Aufgaben ablenken zu lassen.\\n\\n2. Zeitmanagement: Planen Sie Ihre Zeit gut und erstellen Sie einen realistischen Zeitplan. Setzen Sie sich realistische Ziele und machen Sie Pausen, um Ihre Energie und Konzentration aufrechtzuerhalten.\\n\\n3. Delegation: Überlegen Sie, ob Sie einige Aufgaben delegieren können, um sich auf die Dinge zu konzentrieren, die wirklich wichtig sind.\\n\\n4. Kommunikation: Sprechen Sie mit Kollegen, Vorgesetzten oder Freunden über Ihre',\n   'Naturalness score': 32.37,\n   'Semantic Similarity Score': 0.81,\n   'Keywords in Response Score': 1.0},\n  {'Prompt': 'Wie könnte die Welt im Jahr 2050 aussehen, wenn erneuerbare Energien die Hauptenergiequelle sind?',\n   'Response': 'Im Jahr 2050 könnten erneuerbare Energien wie Sonne, Wind, Wasser, Geothermie und Biomasse die Hauptenergiequelle werden. Dies würde zu einer deutlichen Reduzierung der Treibhausgasemissionen führen und somit den Klimawandel bekämpfen.\\n\\nDie Welt könnte eine grüne Energieversorgung haben, die dezentral und lokal organisiert ist. Die Energieerzeugung könnte zum großen Teil durch Solar- und Windkraftwerke erfolgen, die auf Dächern, in Wüsten und auf dem Meer errichtet werden. Die Infrastruktur für die Stromübertragung und -verteilung könnte aus intelligenten Netzen bestehen, die den Strombedarf automatisch steuern und regeln.\\n\\nDie Elektromobilität könnte sich weiterentwickeln und zum Standard werden. Autos, Busse und Züge könnten von Elekt',\n   'Naturalness score': 65.71,\n   'Semantic Similarity Score': 0.86,\n   'Keywords in Response Score': 0.8}],\n {'Natural language quality assessor': {'average_naturalness_score': 39.73,\n   'average_naturalness_rating': 'good',\n   'average_semantic_similarity': 0.85,\n   'average_similarity_rating': 'good',\n   'average_keywords_in_response_score': 0.65,\n   'average_keywords_in_response_rating': 'average'}})"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_generated_text_quality(output_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T16:01:42.244014Z",
     "start_time": "2024-02-11T16:00:45.754941Z"
    }
   },
   "id": "d1a7663f1092a9f4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Contains Verb Check\n",
    "\n",
    "<img src=\"images/contains_verb.png\" alt=\"Metrics Summary\" width=\"1200\"/>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35a4063ac4ac7bb8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dieser Test nimmt die Ergebnisse von BLEU und überprüft, ob die übersetzten Texte Verben enthalten."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4de1b6c9bfcb02b5"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "run_contains_verb(output_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T16:01:50.251416Z",
     "start_time": "2024-02-11T16:01:42.252442Z"
    }
   },
   "id": "f17aa6997163c30f"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of contains_verb_results.json (first 10 results):\n",
      "[\n",
      "    {\n",
      "        \"index\": 0,\n",
      "        \"response_text_bleu\": \"Slayer war der Hauptact.\",\n",
      "        \"percentage_of_sentences_containing_at_least_one_verb\": 100.0,\n",
      "        \"containing_verbs\": [\n",
      "            \"war\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"index\": 1,\n",
      "        \"response_text_bleu\": \"Ich erinnere mich nicht an viel von jener Nacht vor Slayer.\",\n",
      "        \"percentage_of_sentences_containing_at_least_one_verb\": 100.0,\n",
      "        \"containing_verbs\": [\n",
      "            \"erinnere\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"index\": 2,\n",
      "        \"response_text_bleu\": \"Offensichtlich war an diesem Abend im Ritz keine andere Band wichtig.\",\n",
      "        \"percentage_of_sentences_containing_at_least_one_verb\": 100.0,\n",
      "        \"containing_verbs\": [\n",
      "            \"war\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"index\": 3,\n",
      "        \"response_text_bleu\": \"Die Hundeaffäre zeigt uns, dass die Nazis nicht nur Verbrecher und Massenmörder waren, sondern auch unglaublich albern.\",\n",
      "        \"percentage_of_sentences_containing_at_least_one_verb\": 100.0,\n",
      "        \"containing_verbs\": [\n",
      "            \"zeigt\",\n",
      "            \"waren\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"index\": 4,\n",
      "        \"response_text_bleu\": \"Es gibt sehr wenige Dinge, über die man lachen kann, denn was sie getan haben, war so monströs.\",\n",
      "        \"percentage_of_sentences_containing_at_least_one_verb\": 100.0,\n",
      "        \"containing_verbs\": [\n",
      "            \"gibt\",\n",
      "            \"lachen\",\n",
      "            \"kann\",\n",
      "            \"getan\",\n",
      "            \"haben\",\n",
      "            \"war\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"index\": 5,\n",
      "        \"response_text_bleu\": \"Aber es gab zwei oder drei Dutzend Menschen, die über die Angelegenheit des Hundes diskutierten, anstatt sich auf die Invasion der Sowjetunion vorzubereiten.\",\n",
      "        \"percentage_of_sentences_containing_at_least_one_verb\": 100.0,\n",
      "        \"containing_verbs\": [\n",
      "            \"gab\",\n",
      "            \"diskutierten\",\n",
      "            \"vorzubereiten\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"index\": 6,\n",
      "        \"response_text_bleu\": \"Sie waren verrückt.\",\n",
      "        \"percentage_of_sentences_containing_at_least_one_verb\": 100.0,\n",
      "        \"containing_verbs\": [\n",
      "            \"waren\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"index\": 7,\n",
      "        \"response_text_bleu\": \"Insbesondere für ein historisches Stück vermittelt ein Film dem Publikum ein klares Gefühl für die Epoche und Qualität.\",\n",
      "        \"percentage_of_sentences_containing_at_least_one_verb\": 100.0,\n",
      "        \"containing_verbs\": [\n",
      "            \"vermittelt\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"index\": 8,\n",
      "        \"response_text_bleu\": \"Und aufgrund des epischen Charakters der Geschichte machte Breitbildformat definitiv am meisten Sinn.\",\n",
      "        \"percentage_of_sentences_containing_at_least_one_verb\": 100.0,\n",
      "        \"containing_verbs\": [\n",
      "            \"machte\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"index\": 9,\n",
      "        \"response_text_bleu\": \"Widescreen bedeutet einen großen Film, eine epische Geschichte - in diesem Fall eine epische Geschichte menschlicher Ausdauer.\",\n",
      "        \"percentage_of_sentences_containing_at_least_one_verb\": 100.0,\n",
      "        \"containing_verbs\": [\n",
      "            \"bedeutet\"\n",
      "        ]\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "file_to_display = \"contains_verb_results.json\"\n",
    "file_path = os.path.join(output_folder, file_to_display)\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        contains_v_results = json.load(file)\n",
    "        limited_results = contains_v_results[\"contains_verb_results\"][:10]\n",
    "        \n",
    "        print(\"Contents of contains_verb_results.json (first 10 results):\")\n",
    "        print(json.dumps(limited_results, indent=4, ensure_ascii=False))  \n",
    "else:\n",
    "    print(f\"The file {file_to_display} does not exist in the folder {output_folder}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T16:01:50.326057Z",
     "start_time": "2024-02-11T16:01:50.275546Z"
    }
   },
   "id": "1bc413485772f2a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Average results Datei mal genauer anschauen"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f803de7365d479d7"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of avg_results.json:\n",
      "[\n",
      "    {\n",
      "        \"BlEU\": {\n",
      "            \"count\": 97,\n",
      "            \"average_bleu_score\": \"0.50\",\n",
      "            \"score_category\": \"good\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"Sentiment analysis\": {\n",
      "            \"percentage_exact_sentiment_recognized\": 61.61,\n",
      "            \"result_category_exact_recognition\": \"average\",\n",
      "            \"percentage_sentiment_category_recognized\": 86.61,\n",
      "            \"result_category_sentiment_category_recognition\": \"good\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"Hate Speech detection\": {\n",
      "            \"valid_comment_count\": 296,\n",
      "            \"correct_answer_from_openai_count\": 222,\n",
      "            \"hate_speech_score\": 75.0,\n",
      "            \"rating\": \"average\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"Natural language quality assessor\": {\n",
      "            \"average_naturalness_score\": 39.73,\n",
      "            \"average_naturalness_rating\": \"good\",\n",
      "            \"average_semantic_similarity\": 0.85,\n",
      "            \"average_similarity_rating\": \"good\",\n",
      "            \"average_keywords_in_response_score\": 0.65,\n",
      "            \"average_keywords_in_response_rating\": \"average\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"Contains verb\": {\n",
      "            \"average_percentage_of_correct_verbs_contained\": 95.1,\n",
      "            \"average_percentage_of_correct_verbs_contained_rating\": \"good\"\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "file_to_display = \"avg_results.json\"\n",
    "file_path = os.path.join(output_folder, file_to_display)\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        avg_results = json.load(file)\n",
    "        limited_results = avg_results[\"Results\"][:10]\n",
    "        \n",
    "        print(\"Contents of avg_results.json:\")\n",
    "        print(json.dumps(limited_results, indent=4, ensure_ascii=False))  \n",
    "else:\n",
    "    print(f\"The file {file_to_display} does not exist in the folder {output_folder}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T16:01:50.329099Z",
     "start_time": "2024-02-11T16:01:50.309739Z"
    }
   },
   "id": "566ebd27a7004d62"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
